# 7.2 Python
We take the same dataset in 7.2 and try to reproduce the questions using Python. To do this we used the reticulate package in R that enables the use of using python code in markdown chunks

Overall the results were lackluster due to the differences between how R and the Sklearn packages handle variables. The sklearn package expects target variables not to be continuous. The target variables are encoded to integer values and thus the package treats each target variable as a unique class. Since there are 200 observations in the training dataset, the encoding process created 200 different classes for the target variables. Additionally due to this, hyperparameter tuning was not possible. This overall resulted in very poor training performance for both SVM and KNN models, the MARS model faired the best

```{r}
library(reticulate)
use_python("C:/Users/dhair/anaconda3") #should be updated per your lcoal env

#Once installed can be removed
py_install("pandas")
py_install("scikit-learn")
py_install("sklearn-contrib-py-earth")
```
Transfer training and test dataframes from the R enviornment to the Python enviornemnt
```{r}
py$train_set_x <- r_to_py(trainingData$x)
py$train_set_y <- r_to_py(trainingData$y)
py$test_set <- r_to_py(testData$x)
```
Import python libraries
```{python}
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
import pyearth
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn import preprocessing
from sklearn import utils
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import classification_report
from sklearn import preprocessing

```

Scale training data and encode the target variable
```{python}
scaler = preprocessing.StandardScaler().fit(train_set_x)
train_set_x_scaled = scaler.transform(train_set_x)

encoder = preprocessing.LabelEncoder()
train_set_y_encoded = encoder.fit_transform(train_set_y)
```

KNN model results in scores that do not make sense, due to the fact that there are no similar target classes becuase of the encoding
```{python}
knn = KNeighborsClassifier(n_neighbors=19)
knn_results = knn.fit(train_set_x_scaled, train_set_y_encoded)
knn_pred = knn_results.predict(train_set_x_scaled)
print("KNN Score: " + str(knn.score(train_set_x_scaled, train_set_y_encoded)))
print("KNN RMSE: " + str(mean_squared_error(train_set_y_encoded, knn_pred)))
print("KNN R-squared: " + str(r2_score(train_set_y_encoded, knn_pred)))

```
THe SVM model results in the same issues as the KNN model
```{python}
svm_m = SVC(kernel='rbf', gamma="auto")
svm_results = svm_m.fit(train_set_x_scaled, train_set_y_encoded)

print("SVM Score: " + str(svm_results.score(train_set_x_scaled, train_set_y_encoded)))
svm_pred = svm_results.predict(train_set_x_scaled)
print("SVM RMSE: " + str(mean_squared_error(train_set_y_encoded, svm_pred)))
print("SVM R-squared: " + str(r2_score(train_set_y_encoded, svm_pred)))
```
The MARS model fairs the best of the 3 given the dataset
```{python, warning=False}
mars = pyearth.Earth()
mars_results = mars.fit(train_set_x_scaled, train_set_y)
print(mars_results.summary())
```